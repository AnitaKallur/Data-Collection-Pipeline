# Data-Collection-Pipeline
This project demonstrates how webscraping is done using diffent libraries to create python classes using different methods to exctract/collect data from the chosen website from browsing, collecting, saving the data in the database. Below are many milestones to follow in order to complete the project successfully. 

Task 1: Create environment, set up Web driver, install dependencies.
conda create --name Data_Collection_Pipeline

pip3 install selenium
pip3 install pandas

Set up the Web Driver downloading ChromeDriver Manager,
For this Webscraping project had downloaded google-chrome version is 102.0.5005 to be used as a main driver for this project.

![image](https://user-images.githubusercontent.com/98617552/173930898-380f6334-72d8-4d2a-b4f0-93fc73161b6c.png)

