# Data-Collection-Pipeline
This project demonstrates how webscraping is done using diffent libraries to create python classes using different methods to exctract/collect data from the chosen website from browsing, collecting, saving the data in the database. Below are many milestones to follow in order to complete the project successfully. 

Task 1: Create environment, set up Web driver, install dependencies.
conda create --name Data_Collection_Pipeline

pip3 install selenium
pip3 install pandas

Set up the Web Driver downloading ChromeDriver Manager,
For this Webscraping project had downloaded google-chrome version is 102.0.5005 to be used as a main driver for this project.

<img width="1440" alt="Screenshot 2022-06-15 at 22 04 01" src="https://user-images.githubusercontent.com/98617552/173929665-beee311b-82fc-498b-977d-4bd772483aef.png">

