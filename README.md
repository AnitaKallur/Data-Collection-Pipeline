# Data-Collection-Pipeline
This project demonstrates how webscraping is done using diffent libraries to create python classes using different methods to exctract/collect data from the chosen website from browsing, collecting, saving the data in the database. Below are many milestones to follow in order to complete the project successfully. 

Task 1: Create environment, set up Web driver, install dependencies.
conda create --name Data_Collection_Pipeline

pip3 install selenium
pip3 install pandas

Set up the Web Driver downloading ChromeDriver Manager,
For this Webscraping project had downloaded google-chrome version is 102.0.5005 to be used as a main driver for this project.

![image](https://user-images.githubusercontent.com/98617552/173931325-7d3fde90-b44c-4674-a157-e5fd127f2db4.png)


